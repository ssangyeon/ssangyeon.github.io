---
permalink: /
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<style>
  /* í•„ìš”í•œ ë‹¤ë¥¸ CSS ìŠ¤íƒ€ì¼ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì— ì¶”ê°€í•˜ì„¸ìš” */

  .blue-text {
    color: #007bff; /* ì›í•˜ëŠ” íŒŒë€ìƒ‰ Hex Codeë¡œ ë³€ê²½ ê°€ëŠ¥ */
  }
</style>

ğŸ‘‹ Hello! I'm <span class="blue-text">Sangyeon Yoon</span>, an incoming Master's student in <span class="blue-text">Artificial Intelligence</span> at <span class="blue-text">Yonsei University</span>, where I will be fortunate to be advised by Professor <span class="blue-text">Albert No</span>.
I work on <span class="blue-text">privacy, safety, and reasoning</span>. ğŸ¤ If these interests resonate with you, feel free to reach outâ€”I'm always open to collaboration!

<hr>
<h2>News</h2>
<ul>
  <li><b>Aug 2025:</b> Two unlearning papers (<span>R-TOFU</span> and <span>SEPS</span>) have been accepted to EMNLP 2025 Main. See you in China ğŸ‡¨ğŸ‡³! </li>
  <li><b>May 2025:</b> Four new papers are now on arXiv! These include work on safety alignment in reasoning models (<span>SAFEPATH</span>), unlearning benchmarks (<span>DUSK</span> and <span>R-TOFU</span>), and unlearning fragility (<span>SEPS</span>).</li>
  <li><b>Dec 2024:</b> Our paper on sample-based privacy auditing for final model-only scenarios will appear at the NeurIPS 2024 SFLLM Workshop in Canada ğŸ‡¨ğŸ‡¦!</li>
</ul>